{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c609f1a",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "#### Hold-on split -- 80% + 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "187a7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erdos_src/data_processing.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class CFG:\n",
    "    # --- Data & Feature Parameters ---\n",
    "    COIN_ID_COLUMN        = 'coin_id'\n",
    "    TIMESTAMP_COLUMN      = 'timestamp'\n",
    "    TARGET_COLUMN         = 'target_direction'\n",
    "    #PREDICTION_HORIZON_MINS = 10   # predict 10 minutes into the future\n",
    "\n",
    "    # --- Splitting & CV Parameters ---\n",
    "    TRAIN_RATIO           = 0.8    # 80% train, 20% test\n",
    "    SPLIT_ROUND_FREQUENCY = 'month'  # 'month', 'day', or '' for no rounding\n",
    "    CV_SPLITS             = 5\n",
    "\n",
    "\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ALL coins from a partitioned Parquet dataset and\n",
    "    ensure proper sorting.\n",
    "    - path: root folder of the parquet dataset (with coin_id=... subfolders)\n",
    "    Returns a DataFrame with columns including 'coin_id' and 'timestamp'.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Data file not found: {path}\")\n",
    "\n",
    "    # let pandas/pyarrow auto-discover partitions (coin_id, year, etc.)\n",
    "    df = pd.read_parquet(path, engine='pyarrow')\n",
    "\n",
    "    # ensure timestamp is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[CFG.TIMESTAMP_COLUMN]):\n",
    "        df[CFG.TIMESTAMP_COLUMN] = pd.to_datetime(df[CFG.TIMESTAMP_COLUMN])\n",
    "\n",
    "    # sort by coin_id then time\n",
    "    df.sort_values([CFG.COIN_ID_COLUMN, CFG.TIMESTAMP_COLUMN],\n",
    "                   inplace=True, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_data(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Perform a single hold-out split on a time series:\n",
    "    - uses TRAIN_RATIO to locate cutoff between min and max timestamp\n",
    "    - rounds cutoff down to start of month/day if configured\n",
    "    Returns (train_df, test_df), each containing all coins.\n",
    "    \"\"\"\n",
    "    # compute exact cutoff\n",
    "    min_ts = df[CFG.TIMESTAMP_COLUMN].min()\n",
    "    max_ts = df[CFG.TIMESTAMP_COLUMN].max()\n",
    "    total_duration = max_ts - min_ts\n",
    "    exact_cutoff = min_ts + total_duration * CFG.TRAIN_RATIO\n",
    "\n",
    "    # round down if needed\n",
    "    freq = CFG.SPLIT_ROUND_FREQUENCY.lower()\n",
    "    if freq == 'month':\n",
    "        cutoff = exact_cutoff.to_period('M').to_timestamp()\n",
    "    elif freq == 'day':\n",
    "        cutoff = exact_cutoff.normalize()\n",
    "    else:\n",
    "        cutoff = exact_cutoff\n",
    "\n",
    "    # split\n",
    "    train_df = df[df[CFG.TIMESTAMP_COLUMN] < cutoff].copy()\n",
    "    test_df  = df[df[CFG.TIMESTAMP_COLUMN] >= cutoff].copy()\n",
    "\n",
    "    # report\n",
    "    print(f\"Exact split point: {exact_cutoff}\")\n",
    "    print(f\"Rounded split point: {cutoff}\")\n",
    "    print(f\"Train  range: {train_df[CFG.TIMESTAMP_COLUMN].min()} → {train_df[CFG.TIMESTAMP_COLUMN].max()}\")\n",
    "    print(f\"Test   range: {test_df[CFG.TIMESTAMP_COLUMN].min()} → {test_df[CFG.TIMESTAMP_COLUMN].max()}\")\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f307b",
   "metadata": {},
   "source": [
    "#### Data loading & hold-on split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b21f6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact split point: 2024-06-15 16:48:00\n",
      "Rounded split point: 2024-06-01 00:00:00\n",
      "Train  range: 2021-01-01 00:00:00 → 2024-05-31 23:59:00\n",
      "Test   range: 2024-06-01 00:00:00 → 2025-04-27 03:00:00\n",
      "Train shape: (8978400, 14)\n",
      "Test  shape: (2376905, 14)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Locate the data file\n",
    "curr_path = os.getcwd()\n",
    "root_path = os.path.join(curr_path, \"data\", \"OHLCV_ffill.parquet\")\n",
    "\n",
    "# 2. Load ALL coins (no filter)\n",
    "df = load_data(root_path)\n",
    "\n",
    "# 3. Perform the time-based hold-out split\n",
    "train_df, test_df = split_data(df)\n",
    "\n",
    "# 4. Inspect\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test  shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889ee05",
   "metadata": {},
   "source": [
    "#### Get the order of coin_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "626a6582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order of first appearance: ['BNBUSDT', 'BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'XRPUSDT']\n",
      "Lexicographical order: ['BNBUSDT', 'BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'XRPUSDT']\n",
      "Categories (in defined order): ['BNBUSDT', 'BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'XRPUSDT']\n"
     ]
    }
   ],
   "source": [
    "# Assume df contains all coins and is sorted by (coin_id, timestamp)\n",
    "\n",
    "# Method 1: Get the order in which each coin first appears\n",
    "order_appear = df['coin_id'].drop_duplicates().tolist()\n",
    "print(\"Order of first appearance:\", order_appear)\n",
    "\n",
    "# Method 2: Get the coins in lexicographical (alphabetical) order\n",
    "unique_ids    = df['coin_id'].unique().tolist()\n",
    "order_sorted  = sorted(unique_ids)\n",
    "print(\"Lexicographical order:\", order_sorted)\n",
    "\n",
    "# Method 3: Cast to Categorical and inspect the category order\n",
    "df['coin_id'] = df['coin_id'].astype('category')\n",
    "print(\"Categories (in defined order):\", df['coin_id'].cat.categories.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "161d9518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp     open     high      low    close    volume  \\\n",
      "0 2021-01-01 00:00:00  37.3596  37.3702  37.3381  37.3700   807.624   \n",
      "1 2021-01-01 00:01:00  37.3700  37.4221  37.3487  37.3910  2734.241   \n",
      "2 2021-01-01 00:02:00  37.3905  37.4020  37.3298  37.3311   778.868   \n",
      "3 2021-01-01 00:03:00  37.3311  37.3367  37.2729  37.2800   890.907   \n",
      "4 2021-01-01 00:04:00  37.2753  37.2997  37.2502  37.2639   483.711   \n",
      "\n",
      "               close_time  quote_asset_volume  number_of_trades  \\\n",
      "0 2021-01-01 00:00:59.999        30170.884305               146   \n",
      "1 2021-01-01 00:01:59.999       102217.111475               230   \n",
      "2 2021-01-01 00:02:59.999        29092.024959               141   \n",
      "3 2021-01-01 00:03:59.999        33230.401819               156   \n",
      "4 2021-01-01 00:04:59.999        18028.653726               126   \n",
      "\n",
      "   taker_buy_base_asset_volume  taker_buy_quote_asset_volume  missing_flag  \\\n",
      "0                      486.275                  18167.580104             0   \n",
      "1                     1770.005                  66157.450698             0   \n",
      "2                      266.496                   9953.368200             0   \n",
      "3                      284.896                  10625.383029             0   \n",
      "4                      120.471                   4491.430352             0   \n",
      "\n",
      "   coin_id  year  \n",
      "0  BNBUSDT  2021  \n",
      "1  BNBUSDT  2021  \n",
      "2  BNBUSDT  2021  \n",
      "3  BNBUSDT  2021  \n",
      "4  BNBUSDT  2021  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c73866ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  timestamp   open   high    low  close  volume  \\\n",
      "1795680 2024-06-01 00:00:00  593.8  594.1  593.7  594.1  94.447   \n",
      "1795681 2024-06-01 00:01:00  594.1  594.1  593.9  594.0  19.360   \n",
      "1795682 2024-06-01 00:02:00  594.0  594.0  593.9  594.0   5.455   \n",
      "1795683 2024-06-01 00:03:00  594.0  594.2  593.9  594.2  23.386   \n",
      "1795684 2024-06-01 00:04:00  594.1  594.2  594.1  594.2  54.754   \n",
      "\n",
      "                     close_time  quote_asset_volume  number_of_trades  \\\n",
      "1795680 2024-06-01 00:00:59.999          56094.6704                95   \n",
      "1795681 2024-06-01 00:01:59.999          11499.6144                78   \n",
      "1795682 2024-06-01 00:02:59.999           3240.0273                31   \n",
      "1795683 2024-06-01 00:03:59.999          13891.7071                44   \n",
      "1795684 2024-06-01 00:04:59.999          32531.5678                32   \n",
      "\n",
      "         taker_buy_base_asset_volume  taker_buy_quote_asset_volume  \\\n",
      "1795680                       88.239                    52407.8786   \n",
      "1795681                        2.788                     1656.2958   \n",
      "1795682                        3.028                     1798.6320   \n",
      "1795683                       16.062                     9541.3431   \n",
      "1795684                       22.164                    13169.8488   \n",
      "\n",
      "         missing_flag  coin_id  year  \n",
      "1795680             0  BNBUSDT  2024  \n",
      "1795681             0  BNBUSDT  2024  \n",
      "1795682             0  BNBUSDT  2024  \n",
      "1795683             0  BNBUSDT  2024  \n",
      "1795684             0  BNBUSDT  2024  \n"
     ]
    }
   ],
   "source": [
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d7080c",
   "metadata": {},
   "source": [
    "#### Resampling -- 10-min, 1-hour, 4-hour, 1-day intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "840e29b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling train at 10min intervals…\n",
      "  → wrote data/resampled/train_10min.parquet, shape (897840, 11)\n",
      "Resampling train at 1h intervals…\n",
      "  → wrote data/resampled/train_1h.parquet, shape (149640, 11)\n",
      "Resampling train at 4h intervals…\n",
      "  → wrote data/resampled/train_4h.parquet, shape (37410, 11)\n",
      "Resampling train at 1d intervals…\n",
      "  → wrote data/resampled/train_1d.parquet, shape (6235, 11)\n",
      "Resampling test at 10min intervals…\n",
      "  → wrote data/resampled/test_10min.parquet, shape (237695, 11)\n",
      "Resampling test at 1h intervals…\n",
      "  → wrote data/resampled/test_1h.parquet, shape (39620, 11)\n",
      "Resampling test at 4h intervals…\n",
      "  → wrote data/resampled/test_4h.parquet, shape (9905, 11)\n",
      "Resampling test at 1d intervals…\n",
      "  → wrote data/resampled/test_1d.parquet, shape (1655, 11)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1) Ensure output folder exists\n",
    "os.makedirs(\"data/resampled\", exist_ok=True)\n",
    "\n",
    "def resample_ohlcv(df, freq):\n",
    "    \"\"\"\n",
    "    Resample an OHLCV DataFrame (with 'coin_id' column and datetime index on 'timestamp')\n",
    "    to a new frequency.\n",
    "    - df: DataFrame must have a 'coin_id' column and a datetime index named 'timestamp'\n",
    "    - freq: pandas offset alias, e.g. '10min', '1h', '4h', '1d'\n",
    "    Returns a DataFrame with 'coin_id' and 'timestamp' columns restored.\n",
    "    \"\"\"\n",
    "    # set 'timestamp' as the index\n",
    "    df = df.set_index(\"timestamp\")\n",
    "    \n",
    "    # define OHLCV-style aggregations\n",
    "    agg_dict = {\n",
    "        \"open\":                        \"first\",\n",
    "        \"high\":                        \"max\",\n",
    "        \"low\":                         \"min\",\n",
    "        \"close\":                       \"last\",\n",
    "        \"volume\":                      \"sum\",\n",
    "        \"quote_asset_volume\":          \"sum\",\n",
    "        \"number_of_trades\":            \"sum\",\n",
    "        \"taker_buy_base_asset_volume\": \"sum\",\n",
    "        \"taker_buy_quote_asset_volume\":\"sum\"\n",
    "    }\n",
    "    \n",
    "    # group by coin_id (only observed categories) and resample\n",
    "    out = (\n",
    "        df\n",
    "        .groupby(\"coin_id\", observed=True)\n",
    "        .resample(freq)\n",
    "        .agg(agg_dict)\n",
    "        .dropna(subset=[\"open\"])  # remove empty intervals\n",
    "        .reset_index()\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "# 3) Define the frequencies and their labels\n",
    "freq_map = {\n",
    "    \"10min\": \"10min\",\n",
    "    \"1h\":    \"1h\",\n",
    "    \"4h\":    \"4h\",\n",
    "    \"1d\":    \"1d\",\n",
    "}\n",
    "\n",
    "# 4) Loop over train/test DataFrames, resample & save\n",
    "for df_name, df in [(\"train\", train_df), (\"test\", test_df)]:\n",
    "    for freq, label in freq_map.items():\n",
    "        print(f\"Resampling {df_name} at {label} intervals…\")\n",
    "        rs = resample_ohlcv(df, freq)\n",
    "        out_path = os.path.join(\"data\", \"resampled\", f\"{df_name}_{label}.parquet\")\n",
    "        rs.to_parquet(out_path)\n",
    "        print(f\"  → wrote {out_path}, shape {rs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706b78b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
